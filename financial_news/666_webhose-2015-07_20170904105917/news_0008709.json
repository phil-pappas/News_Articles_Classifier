{"organizations": [], "uuid": "8efc63333f82faa70bed93585c4577c3fe4900c0", "thread": {"social": {"gplus": {"shares": 0}, "pinterest": {"shares": 0}, "vk": {"shares": 0}, "linkedin": {"shares": 0}, "facebook": {"likes": 0, "shares": 0, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "www.afr.com", "main_image": "http://www.afr.com/content/dam/images/g/i/l/b/z/j/image.related.afrArticleLead.620x365.gilbab.png/1437991240305.jpg", "site_section": "http://www.afr.com/", "section_title": "Financial Review - Business, Finance and Investment News | afr.com", "url": "http://www.afr.com/opinion/columns/dont-judge-measure-character-with-algorithms-20150727-gilbab", "country": "AU", "title": "Don't judge: measure character with algorithms", "performance_score": 0, "site": "afr.com", "participants_count": 1, "title_full": "Don't judge: measure character with algorithms | afr.com", "spam_score": 0.0, "site_type": "news", "published": "2015-07-27T12:40:00.000+03:00", "replies_count": 0, "uuid": "8efc63333f82faa70bed93585c4577c3fe4900c0"}, "author": "Quentin Hardy", "url": "http://www.afr.com/opinion/columns/dont-judge-measure-character-with-algorithms-20150727-gilbab", "ord_in_thread": 0, "title": "Don't judge: measure character with algorithms", "locations": [], "entities": {"persons": [], "locations": [], "organizations": []}, "highlightText": "", "language": "english", "persons": [], "text": "Upstart judges loan applications on data-driven analysis of personality rather than standard measures. by Quentin Hardy Computers aren't just doing hard maths problems and showing us cat videos. Increasingly, they judge our character.\nMaybe we should be grateful.\nA company in Palo Alto, California, called Upstart has over the past 15 months lent $US130 million ($178 million) to people with mostly negligible credit scores. Typically, they are recent graduates without mortgages, car payments or credit card histories.\nThose are among the things that normally earn a good or bad credit score, but these people haven't been in the working world that long. So Upstart looks at their SAT scores, which colleges they attended, their majors and their grade point averages. As much as job prospects, the company is assessing personality.\n\"If you take two people with the same job and circumstances, like whether they have kids, five years later the one who had the higher GPA is more likely to pay a debt,\" says Paul Gu, Upstart's co-founder and head of product. \"It's not whether you can pay. It's a question of how important you see your obligation.\"\nThe idea, validated by data, is that people who did things like double-checking their homework or studying extra in case there was a pop quiz are thorough and likely to honour their debts.\nAnalytics, meet judgment of people.\n\"I guess you could call it character, though we haven't used that label,\" says Gu, 24.\n The same personality dynamic holds for people who did not go to great schools or have top grades.\nDouglas Merrill, the founder and chief executive of ZestFinance, is a former Google executive whose company writes loans to subprime borrowers through non-standard data signals.\nOne signal is whether someone has ever given up a prepaid wireless phone number. Where housing is often uncertain, those numbers are a more reliable way to find you than addresses; giving one up may indicate you are willing (or have been forced) to disappear from family or potential employers. That is a bad sign.\nZest recently branched into \"near prime\" borrowers, who have either fallen from the prime category or risen from subprime. The question is why these people have changed categories, and Zest tries to figure out if a potentially reliable borrower has had some temporary bad luck, such as a one-time medical expense.\n\"'Character' is a loaded term, but there is an important difference between ability to pay and willingness to pay,\" Merrill said. \"If all you look at is financial transactions, it's hard to say much about willingness.\"\nFairer system Merrill, who also has a PhD in psychology (from Princeton, in case Gu wants to lend him money), thinks that data-driven analysis of personality is ultimately fairer than standard measures.\n\"We're always judging people in all sorts of ways, but without data we do it with a selection bias,\" he says. \"We base it on stuff we know about people, but that usually means favouring people who are most like ourselves.\" Familiarity is a crude form of risk management, because we know what to expect. But that doesn't make it fair.\nCharacter (though it is usually called something more neutral-sounding) is now judged by many other algorithms. Workday, a company offering cloud-based personnel software, has released a product that looks at 45 employee performance factors, including how long a person has held a position and how well the person has done. It predicts whether a person is likely to quit and suggests appropriate things, such as a new job or a transfer, that could make this kind of person stay.\nIt can also characterise managers as \"rainmakers\" or \"terminators\" depending on how well they hold talent. Inside Workday, the company has analysed its own sales force to see what makes for success. The top indicator is tenacity.\n\"We all have biases about how we hire and promote,\" says Dan Beck, Workday's head of technology strategy. \"If you can leverage data to overcome that, great.\"\nPeople studying these traits will be encouraged to adopt them, he says, because \"if you know there is a pattern of success, why wouldn't you adopt it?\"\nIn a sense, it's no different from the way people read the biographies of high achievers, looking for clues for what they need to do differently to succeed. It's just at a much larger scale, based on observing everybody.\nThere are reasons to think that data-based character judgments are more reasonable.\nJure Leskovec, a professor of computer science at Stanford, is finishing a study comparing the predictions of data analysis against those of judges at bail hearings, who have just a few minutes to size up prisoners and decide if they could be risks to society. Early results indicate that data-driven analysis is 30 per cent better at predicting crime, Leskovec says.\n\"Algorithms aren't subjective,\" he says. \"Bias comes from people.\"\nThat is only true to a point: algorithms do not fall from the sky. Algorithms are written by human beings. Even if the facts aren't biased, design can be, and we could end up with a flawed belief that maths is always truth.\nUpstart's Gu, who says he had perfect SAT scores but dropped out of Yale, wouldn't have qualified for an Upstart loan using his own initial algorithms. He has since changed the design, and he says he is aware of the responsibility of the work ahead.\n\"Every time we find a signal, we have to ask ourselves, 'Would we feel comfortable telling someone this was why they were rejected?'\" he says.\nQuentin Hardy is deputy technology editor for The New York Times.\nNew York Times", "external_links": [], "published": "2015-07-27T12:40:00.000+03:00", "crawled": "2015-07-27T20:04:35.050+03:00", "highlightTitle": ""}