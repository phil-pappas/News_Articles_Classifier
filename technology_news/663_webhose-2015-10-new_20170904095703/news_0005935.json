{"organizations": [], "uuid": "3b231fbd946dbdbb6f9502aab1ba2c0015e3f955", "thread": {"social": {"gplus": {"shares": 0}, "pinterest": {"shares": 0}, "vk": {"shares": 0}, "linkedin": {"shares": 0}, "facebook": {"likes": 0, "shares": 0, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "news.morningstar.com", "main_image": "", "site_section": "http://news.morningstar.com/all/dow-jones/technology.aspx", "section_title": "News Archive: Technology", "url": "http://news.morningstar.com/all/dow-jones/technology/2015101411041/more-devices-gain-3-d-vision.aspx", "country": "US", "title": "More Devices Gain 3-D Vision", "performance_score": 0, "site": "morningstar.com", "participants_count": 1, "title_full": "More Devices Gain 3-D Vision", "spam_score": 0.0, "site_type": "news", "published": "2015-10-14T03:00:00.000+03:00", "replies_count": 0, "uuid": "3b231fbd946dbdbb6f9502aab1ba2c0015e3f955"}, "author": "morningstar.com", "url": "http://news.morningstar.com/all/dow-jones/technology/2015101411041/more-devices-gain-3-d-vision.aspx", "ord_in_thread": 0, "title": "More Devices Gain 3-D Vision", "locations": [], "entities": {"persons": [], "locations": [], "organizations": []}, "highlightText": "", "language": "english", "persons": [], "text": "By Jack Nicas\nFaster, cheaper computer processors are enabling more devices to \"see\" in three dimensions, spawning drones that can avoid trees, robots that can skirt furniture and security cameras that can tell a homeowner from an intruder.\nMany of the new devices combine images from two side-by-side cameras, simulating how humans see. Until recently, such an approach would have been too expensive, bulky and power-hungry.\n\"Not too long ago, this was only available in million-dollar robots,\" said Larry Yang, head of a computer-vision initiative at Alphabet Inc., the company formerly known as Google.\nThe rise of smartphones has improved processors and sensors to make so-called computer vision commercially viable in small, inexpensive devices, he said. \"It's a combination of four things: size, processing power, power consumption and cost.\"\nAlphabet wants computer vision to enhance its Android smartphone software and says two manufacturers plan to incorporate the technology into smartphones next year.\nComputer makers have now put Intel Corp.'s computer-vision technology, dubbed RealSense, into more than 25 models of laptops and tablets. RealSense enables those devices to scan objects and people in three dimensions, allowing users to put the image in a computer game or 3-D print a miniature model.\nAt an Intel event in August, Chief Executive Brian Krzanich touted vending machines that can be controlled with a wave of a hand and digital mirrors that allow people to virtually try on clothes. Intel has 500 employees working on RealSense, up from 25 when the project began in 2011.\nRealSense can give a device 3-D vision via a four-millimeter-thick strip that includes two cameras and an integrated processor. By comparison, when Microsoft Corp.'s Kinect incorporated players' movements into videogames in an early consumer-tech version of computer vision in 2010, it required a nearly foot-long box that relied on the Xbox's processors.\nEngineers have long used radar, sonar, lasers and other techniques to calculate depth, but the expense limited their use to large commercial applications, such as factory robots and the first-down line on TV football broadcasts.\nWith computer vision, robots can leave their stationary posts in factories and navigate the real world. In Silicon Valley, robots now deliver toothbrushes to hotel rooms and lead customers to the plumbing section of a hardware store, avoiding obstacles and navigating aisles along the way.\nThe first Roomba robotic vacuum bumped into objects as it moved around homes, a technique adopted from military robots that cleared land mines. Last month, iRobot Corp. released a Roomba with computer vision that can map and navigate a home, sharply increasing its efficiency.\n\"This is what robotics has needed for the last 25 years,\" said iRobot CEO Colin Angle. \"For decades, there have been [computer] programs that can parse the sentence 'Go bring me a beer,' and know what to do. The challenge is: Where's the kitchen? What's a refrigerator? How do I open it? What's a beer look like? How do I grab it? And where do I go once I have it?\"\nParis-based Blue Frog Robotics SAS had planned to ship Buddy, a home robot with cartoonish eyes, without computer vision next year because of the cost. Executives changed their minds when they realized they could include the technology for $20, down from $200 two years ago, a Blue Frog executive estimated. Now Buddy can recognize family members and remember where the kitchen is.\nComputer vision is enabling drones to avoid obstacles in flight, a key issue for regulators weighing plans by Alphabet and Amazon.com Inc. to deliver packages by drone. The world's biggest consumer drone maker, SZ DJI Technology Co. of Shenzhen, China, released a drone for developers in June that can avoid obstacles. The firm expects the technology to soon reach its consumer devices.\nIntel and fellow chip maker Qualcomm Inc. are working with drone makers on collision-avoidance technology. Chris Anderson, chief executive of drone maker 3D Robotics Inc., said those companies are helping the field advance even faster. \"When computer vision becomes baked into everything, we get really smart,\" he said.\nAlphabet is pushing technology that would add two cameras to smartphones and tablets--one to calculate depth and one to track the device's movement. With the technology, the devices will be able to quickly measure the dimensions of a room, or display digital objects in a camera's view of the real world--a technology called augmented reality that can be used to test how new furniture would look in a room, for instance.\nAlphabet is most excited about the technology's potential to enable devices to figure out their locations within a centimeter or about a half inch. A device equipped with computer vision and a 3-D model of its environment would be able to compute its location just by \"looking.\" That is how robots and Alphabet's self-driving cars navigate the world. Alphabet is building a virtual model of the real world, which it believes will potentially help the technology replace Global Positioning System data as the primary way to locate a user.\nWrite to Jack Nicas at jack.nicas@wsj.com\n 14, 2015 18:08 ET (22:08 ", "external_links": ["http://im.mstar.com/Im/Mbr/Form_PremCheckbox_Checked.gif", "http://s7.addthis.com/static/btn/sm-share-en.gif", "http://www.addthis.com/bookmark.php?v=250", "http://im.mstar.com/Im/Mbr/Form_PremCheckbox_Unchecked.gif"], "published": "2015-10-14T03:00:00.000+03:00", "crawled": "2015-10-15T03:35:00.854+03:00", "highlightTitle": ""}