{"organizations": [], "uuid": "c81296cfa6767b457d4ba12174122cf94d828081", "thread": {"social": {"gplus": {"shares": 0}, "pinterest": {"shares": 0}, "vk": {"shares": 0}, "linkedin": {"shares": 0}, "facebook": {"likes": 0, "shares": 0, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "www.nytimes.com", "main_image": "http://static01.nyt.com/images/2015/10/25/opinion/sunday/25lohr/25lohr-facebookJumbo.jpg", "site_section": "http://www.nytimes.com/services/xml/rss/nyt/Technology.xml", "section_title": "NYT > Technology", "url": "http://www.nytimes.com/2015/10/25/sunday-review/dont-fear-the-robots.html?partner=rss&emc=rss&_r=0", "country": "US", "title": "News Analysis: Don’t Fear the Robots", "performance_score": 5, "site": "nytimes.com", "participants_count": 1, "title_full": "News Analysis: Don’t Fear the Robots", "spam_score": 0.0, "site_type": "news", "published": "2015-10-24T21:30:00.000+03:00", "replies_count": 0, "uuid": "c81296cfa6767b457d4ba12174122cf94d828081"}, "author": "STEVE LOHR", "url": "http://www.nytimes.com/2015/10/25/sunday-review/dont-fear-the-robots.html?partner=rss&emc=rss&_r=0", "ord_in_thread": 0, "title": "News Analysis: Don’t Fear the Robots", "locations": [], "entities": {"persons": [], "locations": [], "organizations": []}, "highlightText": "", "language": "english", "persons": [], "text": "Continue reading the main story Big companies and start-ups are beginning to use learning software in higher-stakes decisions like medical diagnosis, crime prevention, hiring selections and loan approvals. The idea is that an A.I. turbocharger can be applied to all kinds of decisions, making them smarter, fairer and less prone to human whim and bias. The goal could be saving money or saving lives. Still, even enthusiasts have qualms. Take consumer lending, a market where several start-ups are using big data and algorithms to assess the credit risk of borrowers. It’s a digital-age twist on the most basic tenet of banking: Know your customer. By harvesting data from many sources, including social network connections, even observing how an applicant fills out online forms, lenders say algorithms can more accurately predict whether a candidate will repay than by simply looking at a person’s credit history. The promise is more efficient loan underwriting and pricing, saving consumers billions of dollars. But the new A.I. lending essentially amounts to a digital black box that pores over mountains of data. “A decision is made about you, and you have no idea why it was done,” said Rajeev Date, a former deputy director of the Consumer Financial Protection Bureau. “That is disquieting.” Dr. Herbert Chase, a professor at Columbia’s College of Physicians and Surgeons, was asked as an unpaid researcher to try out IBM’s Watson software when the company’s scientists were adapting the technology for medicine. To try to stump Watson, Dr. Chase recalled a case decades earlier, when he made a correct diagnosis of adult rickets for a young woman, but only after extensive tests and months of being baffled. He fed Watson a few symptoms and the program, which ranks diagnoses by probability, swiftly replied and ranked adult rickets second. Not perfect, but Dr. Chase was impressed that the technology was so close and so fast. He thinks Watson-like software, which can scan and mine many thousands of medical articles in a few seconds, will be part of the future of medicine, assisting doctors inundated with information and short of time. But his nagging concern is that over time “we come to trust the technology too much, that it becomes the medical equivalent of blindly following a GPS system on your car down a dead end,” Dr. Chase said. This, of course, is a central issue as these intelligent systems — whether software programs or robots — evolve. Will they be servants or masters? “Even if these systems are consistently right, slavishly following their instructions robs us of our ability to decide on our own,” said Kristian Hammond, an artificial intelligence expert at Northwestern University. “Then you actually get the world no one wants. The machine algorithm tells us what to do.” The antidote is what Mr. Hammond calls “transparency” and others call “storytelling” — an explanation of the data ingredients that go into an automated decision and how it is made. University scientists and corporate researchers are working on A.I.-monitoring technology that ranges from data audit trails to English-language accounts of an algorithm’s chain of reasoning. Meanwhile, new research initiatives have sprung up that seem to have in mind that distant date when robots might achieve independence from their human masters. At Stanford, a group of leading scientists has begun a 100-year study on artificial intelligence. Mr. Musk has put millions of dollars into research grants sponsored by the Future of Life Institute , which is focused on guiding A.I. down beneficial paths. But for the near term, it’s those unseen algorithms — far more than robots — that deserve a watchful human eye. The stakes, some experts say, extend far beyond mere technology. “We need to make sure that the data and algorithms are continuously reviewed and vetted by a broad class of people,” said Alex Pentland, a computational social scientist at the M.I.T. Media Lab. “Think of representative democracy, forging algorithms rather than laws.” \nSteve Lohr is a technology reporter for The New York Times and the author of “Data-ism.’’ A version of this news analysis appears in print on October 25, 2015, on page SR2 of the New York edition with the headline: Don’t Fear the Robots. Order Reprints | Today's Paper | Subscribe Loading...", "external_links": [], "published": "2015-10-24T21:30:00.000+03:00", "crawled": "2015-10-25T00:24:37.972+03:00", "highlightTitle": ""}