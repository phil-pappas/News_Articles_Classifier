{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source of the JSON files can be found <a href=\"https://webhose.io/free-datasets/political-news-articles/\">here</a> \n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Please note: </h5>\n",
    "In order to avoid memory errors you have to use Python's 64-bit version (because 32-bit uses limited memory)\n",
    "Plus, I broke down the different datasets in individual pickles and then I combined them together into one to avoid losing data during the extraction process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Installing all the required libraries </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h3>Entertainment news</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mac\n",
    "#path = '/Users/<username here>/Projects/News_Dataset_Creation/entertainment_news/'\n",
    "\n",
    "#windows path\n",
    "path = 'C:\\\\Users\\\\Phil\\\\Projects\\\\News_Dataset_Creation\\\\entertainment_news'\n",
    "\n",
    "files = []\n",
    "titles = []\n",
    "texts = []\n",
    "\n",
    "\n",
    "\n",
    "#List all the files within this folder and find those that are ending with .json extension\n",
    "for r, d, f in os.walk(path): # r=root, d=directories, f = files\n",
    "    for file in f: \n",
    "        if '.json' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "\n",
    "# Get the 'title' and the 'text' of each article\n",
    "for file_number in files:\n",
    "    with open (file_number, errors='ignore') as f:\n",
    "        data = json.load(f)\n",
    "        titles.append(data['title']) \n",
    "        texts.append(data['text'])\n",
    "        \n",
    "df_entertainment = pd.DataFrame(\n",
    "        {'Title': titles,\n",
    "         'Text': texts,\n",
    "         'Category': 'entertainment'})\n",
    "titles.clear()\n",
    "texts.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entertainment.to_pickle('pickles/entertainment')\n",
    "df_entertainment.iloc[0:0]#clear the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Financial news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\Phil\\\\Projects\\\\News_Dataset_Creation\\\\financial_news'\n",
    "\n",
    "files = []\n",
    "titles = []\n",
    "texts = []\n",
    "\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.json' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "\n",
    "\n",
    "for file_number in files:\n",
    "    with open (file_number, errors='ignore') as f:\n",
    "        data = json.load(f)\n",
    "        titles.append(data['title'])\n",
    "        texts.append(data['text'])\n",
    "        \n",
    "df_financial = pd.DataFrame(\n",
    "        {'Title': titles,\n",
    "         'Text': texts,\n",
    "         'Category': 'financial'})\n",
    "titles.clear()\n",
    "texts.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all_news = df_all_news.append(df_financial, ignore_index=True)\n",
    "df_financial.to_pickle('pickles/financial')\n",
    "df_financial.iloc[0:0]#clear the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Political news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\Phil\\\\Projects\\\\News_Dataset_Creation\\\\political_news'\n",
    "\n",
    "files = []\n",
    "titles = []\n",
    "texts = []\n",
    "\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.json' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "\n",
    "\n",
    "for file_number in files:\n",
    "    with open (file_number, errors='ignore') as f:\n",
    "        data = json.load(f)\n",
    "        titles.append(data['title'])\n",
    "        texts.append(data['text'])\n",
    "        \n",
    "df_political = pd.DataFrame(\n",
    "        {'Title': titles,\n",
    "         'Text': texts,\n",
    "         'Category': 'political'})\n",
    "titles.clear()\n",
    "texts.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all_news = df_all_news.append(df_political, ignore_index=True)\n",
    "df_political.to_pickle('pickles/political')\n",
    "df_political.iloc[0:0]#clear the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sport news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\Phil\\\\Projects\\\\News_Dataset_Creation\\\\sport_news'\n",
    "\n",
    "files = []\n",
    "titles = []\n",
    "texts = []\n",
    "\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.json' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "\n",
    "\n",
    "for file_number in files:\n",
    "    with open (file_number, errors='ignore') as f:\n",
    "        data = json.load(f)\n",
    "        titles.append(data['title'])\n",
    "        texts.append(data['text'])\n",
    "        \n",
    "df_sport = pd.DataFrame(\n",
    "        {'Title': titles,\n",
    "         'Text': texts,\n",
    "         'Category': 'sport'})\n",
    "titles.clear()\n",
    "texts.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all_news = df_all_news.append(df_sport, ignore_index=True)\n",
    "df_sport.to_pickle('pickles/sport')\n",
    "df_sport.iloc[0:0]#clear the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technology news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\Phil\\\\Projects\\\\News_Dataset_Creation\\\\technology_news'\n",
    "\n",
    "files = []\n",
    "titles = []\n",
    "texts = []\n",
    "\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.json' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "\n",
    "\n",
    "for file_number in files:\n",
    "    with open (file_number, errors='ignore') as f:\n",
    "        data = json.load(f)\n",
    "        titles.append(data['title'])\n",
    "        texts.append(data['text'])\n",
    "        \n",
    "df_technology = pd.DataFrame(\n",
    "        {'Title': titles,\n",
    "         'Text': texts,\n",
    "         'Category': 'technology'})\n",
    "\n",
    "titles.clear()\n",
    "texts.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_technology.to_pickle('pickles/technology')\n",
    "df_technology.iloc[0:0]#clear the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Travel news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\Phil\\\\Projects\\\\News_Dataset_Creation\\\\travel_news'\n",
    "\n",
    "files = []\n",
    "titles = []\n",
    "texts = []\n",
    "\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.json' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "\n",
    "\n",
    "for file_number in files:\n",
    "    with open (file_number, errors='ignore') as f:\n",
    "        data = json.load(f)\n",
    "        titles.append(data['title'])\n",
    "        texts.append(data['text'])\n",
    "        \n",
    "df_travel = pd.DataFrame(\n",
    "        {'Title': titles,\n",
    "         'Text': texts,\n",
    "         'Category': 'travel'})\n",
    "\n",
    "\n",
    "titles.clear()\n",
    "texts.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_travel.to_pickle('pickles/travel')\n",
    "df_travel.iloc[0:0]#clear the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### World news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\Phil\\\\Projects\\\\News_Dataset_Creation\\\\world_news'\n",
    "\n",
    "files = []\n",
    "titles = []\n",
    "texts = []\n",
    "\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.json' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "\n",
    "\n",
    "for file_number in files:\n",
    "    with open (file_number, errors='ignore') as f:\n",
    "        data = json.load(f)\n",
    "        titles.append(data['title'])\n",
    "        texts.append(data['text'])\n",
    "        \n",
    "df_world = pd.DataFrame(\n",
    "        {'Title': titles,\n",
    "         'Text': texts,\n",
    "         'Category': 'world'})\n",
    "\n",
    "\n",
    "titles.clear()\n",
    "texts.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_world.to_pickle('pickles/world')\n",
    "df_world.iloc[0:0]#clear the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entertainment = pd.read_pickle('pickles/entertainment')\n",
    "df_financial = pd.read_pickle('pickles/financial')\n",
    "df_political = pd.read_pickle('pickles/political')\n",
    "df_sport = pd.read_pickle('pickles/sport')\n",
    "df_technology = pd.read_pickle('pickles/technology')\n",
    "df_travel = pd.read_pickle('pickles/travel')\n",
    "df_world = pd.read_pickle('pickles/world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the dtaframes into one\n",
    "frames = [df_entertainment, df_financial, df_political, df_sport, df_technology, df_travel, df_world]\n",
    "df_all_news = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the final dataframe to excel and to a dataframe \n",
    "# (May run for several minutes)\n",
    "df_all_news.to_pickle('pickles/all_news')\n",
    "df_all_news.to_excel(\"all_news.xlsx\")\n",
    "df_all_news.iloc[0:0]#clear the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
