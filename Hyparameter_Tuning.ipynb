{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run packages_imported.py\n",
    "%run EDA.py\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all_news_processed = pd.read_pickle(r'data/original_data/pickles/df_all_news_processed_post_dataset_distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1 = df_all_news_processed.loc[df_all_news_processed['Category'] == 'entertainment'][:1000]\n",
    "frame2 = df_all_news_processed.loc[df_all_news_processed['Category'] == 'financial'][:1000]\n",
    "frame3 = df_all_news_processed.loc[df_all_news_processed['Category'] == 'political'][:1000]\n",
    "frame4 = df_all_news_processed.loc[df_all_news_processed['Category'] == 'sport'][:1000]\n",
    "frame5 = df_all_news_processed.loc[df_all_news_processed['Category'] == 'technology'][:1000]\n",
    "frame6 = df_all_news_processed.loc[df_all_news_processed['Category'] == 'world'][:1000]\n",
    "frame7 = df_all_news_processed.loc[df_all_news_processed['Category'] == 'travel'][:1000]\n",
    "\n",
    "frames = [frame1, frame2, frame3, frame4, frame5, frame6, frame7]\n",
    "df_processed_smaller = pd.concat(frames)\n",
    "df_processed_smaller.reset_index()\n",
    "df_processed_smaller.to_pickle('data/original_data/pickles/df_processed_smaller_before_tuning')"
   ]
  },
  {
   "source": [
    "--------"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_news_processed = pd.read_pickle(r'data/original_data/pickles/df_processed_smaller_before_tuning')"
   ]
  },
  {
   "source": [
    "t1 = time.time() \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7)\n",
    "X = tfidfconverter.fit_transform(df_all_news_processed['Text']).toarray()\n",
    "\n",
    "EDA.process_time(round(time.time()-t1))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Process completed.\nTime taken: 2 seconds\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'max_features': 'log2', 'n_estimators': 700}\nProcess completed.\nTime taken: 2mins 11secs\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time() \n",
    "\n",
    "y = df_all_news_processed['Category']\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "r_f_c = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, random_state=0)\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 700],\n",
    "    'max_features': ['auto', 'log2']\n",
    "}\n",
    "CV_rfc = GridSearchCV(estimator=r_f_c, param_grid=param_grid, cv= 5)\n",
    "\n",
    "CV_rfc.fit(X_train, y_train) \n",
    "print (CV_rfc.best_params_)\n",
    "EDA.process_time(round(time.time()-t1))"
   ]
  },
  {
   "source": [
    "## Naive Bayes (Multinomial?)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "X = df_all_news_processed['Text']\n",
    "Y = df_all_news_processed['Category']\n",
    "distinct_categories = Y.drop_duplicates()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('Vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('TFiDF-tr',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('MNB',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "algo_pipe = Pipeline([('Vect', CountVectorizer()),\n",
    "               ('TFiDF-Tr', TfidfTransformer()),\n",
    "               ('MNB', MultinomialNB())])\n",
    "\n",
    "algo_pipe.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score: 0.66429\n               precision    recall  f1-score   support\n\nentertainment       0.69      0.81      0.74       203\n    financial       0.64      0.78      0.70       224\n    political       0.69      0.40      0.51       178\n        sport       0.82      0.67      0.74       215\n   technology       0.54      0.66      0.59       183\n        world       0.69      0.72      0.70       186\n       travel       0.63      0.58      0.60       211\n\n     accuracy                           0.66      1400\n    macro avg       0.67      0.66      0.66      1400\n weighted avg       0.67      0.66      0.66      1400\n\n"
     ]
    }
   ],
   "source": [
    "Y_pred = algo_pipe.predict(X_test)\n",
    "######\n",
    "print('Accuracy score: %s' % round(accuracy_score(Y_pred, Y_test), 5))\n",
    "#algo_pipe.score(X_test, Y_test)\n",
    "#####\n",
    "print(classification_report(Y_test, Y_pred,target_names=distinct_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "tuned_parameters = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__fit_prior': [True, False],\n",
    "    'clf__alpha': [1, 0.6, 0.1, 1e-2, 1e-3, 1e-4]\n",
    "}\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "               precision    recall  f1-score   support\n\nentertainment     0.7419    0.7931    0.7667       203\n    financial     0.7034    0.7411    0.7217       224\n    political     0.6125    0.5506    0.5799       178\n        sport     0.8242    0.6977    0.7557       215\n   technology     0.5614    0.6995    0.6229       183\n       travel     0.7500    0.7258    0.7377       186\n        world     0.6345    0.5924    0.6127       211\n\n     accuracy                         0.6879      1400\n    macro avg     0.6897    0.6857    0.6853      1400\n weighted avg     0.6932    0.6879    0.6882      1400\n\nBest Score:  0.7008928571428571\nBest Params:  {'clf__alpha': 0.01, 'clf__fit_prior': False, 'tfidf__max_df': 0.5, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\nProcess completed.\nTime taken: 4h 48mins 22secs\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time() \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "clf = GridSearchCV(text_clf, tuned_parameters, cv=10, scoring='accuracy')\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "print(classification_report(Y_test, clf.predict(X_test), digits=4))\n",
    "\n",
    "print(\"Best Score: \", clf.best_score_)\n",
    "print(\"Best Params: \", clf.best_params_)\n",
    "EDA.process_time(round(time.time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.6, 'clf__fit_prior': False, 'tfidf__norm': 'l1'}"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6883928571428571"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "source": [
    "## Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## XGBoost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Support Vector Machine (SVM)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## K Nearest Neighbour (?)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}