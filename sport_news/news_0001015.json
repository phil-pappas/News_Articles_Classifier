{"organizations": [], "uuid": "aa46049a0d94e8bffdf033e6b22f8a35313c8474", "thread": {"social": {"gplus": {"shares": 0}, "pinterest": {"shares": 0}, "vk": {"shares": 0}, "linkedin": {"shares": 0}, "facebook": {"likes": 0, "shares": 0, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "www.chicagotribune.com", "main_image": "http://www.trbimg.com/img-56211e8a/turbine/ct-humanities-festival-sylvester-johnson-ae-1018-20151015", "site_section": "http://www.chicagotribune.com/", "section_title": "Chicago Tribune: Chicago breaking news, sports, business, entertainment, weather and traffic - Chicago Tribune", "url": "http://www.chicagotribune.com/entertainment/movies/ct-humanities-festival-sylvester-johnson-ae-1018-20151015-column.html", "country": "US", "title": "Humanities Fest preview on artificial intelligence - Chicago Tribune", "performance_score": 0, "site": "chicagotribune.com", "participants_count": 1, "title_full": "Humanities Fest preview on artificial intelligence - Chicago Tribune", "spam_score": 0.0, "site_type": "news", "published": "2015-10-16T19:54:00.000+03:00", "replies_count": 0, "uuid": "aa46049a0d94e8bffdf033e6b22f8a35313c8474"}, "author": "Nina Metz", "url": "http://www.chicagotribune.com/entertainment/movies/ct-humanities-festival-sylvester-johnson-ae-1018-20151015-column.html", "ord_in_thread": 0, "title": "Humanities Fest preview on artificial intelligence - Chicago Tribune", "locations": [], "entities": {"persons": [], "locations": [], "organizations": []}, "highlightText": "", "language": "english", "persons": [], "text": "Forget any dread you may have about a rise of the machines. They have already risen, and are autocorrecting our texts and supplying driving directions through GPS. The increasing presence of artificial intelligence in our lives poses all kinds of moral and techno-philosophical questions including the biggest of all: As machines become nearly indistinguishable from people, what does it even mean to be human?\n\"We are able to engineer machines to perform human tasks, and many scientists will tell you that machines can think,\" Sylvester Johnson said, when we spoke recently about his upcoming Chicago Humanities Festival event, \"Of Machines and Men.\"\nJohnson, an associate professor at Northwestern University, is working on a study of intelligent machines and their challenge to human exceptionalism. \"Being human,\" he said, \"is really manifested through the cognitive — through thinking and reasoning and showing empathy — so what happens when machines can do that?\"\nThe possibilities that spring to mind tend to have a dystopian tinge, don't they? But while reading up on AI, I stumbled upon this anonymous observation in the comments section of an article: \"What rational person could look at what humanity has done to itself and to this world but believe that a machine super-intelligence would do worse? In my opinion, these fears are irrational and arrogant.\"\nMaybe? Let's hope.\nQ: What are some examples of AI that we interact with right now that we're not really aware of on a conscious level?\nA: Machines are creating music. They can actually create novels; you can go on Amazon today and purchase books that are written by a machine. Many of the newspaper articles you see today are written by machines. There are several companies that sell software to news agencies throughout the world that can use machines to write articles.\nChicago Humanities Festival: Everything you need to know Steve Johnson What: The Chicago Humanities Festival annually presents more than 100 events at venues across Chicago and in Evanston. The lectures, conversations, plays, films, art events and tours are generally, but not strictly, organized around a theme. This year it is \"Citizens,\" which means lots of material...\nWhat: The Chicago Humanities Festival annually presents more than 100 events at venues across Chicago and in Evanston. The lectures, conversations, plays, films, art events and tours are generally, but not strictly, organized around a theme. This year it is \"Citizens,\" which means lots of material...\n(Steve Johnson) (Sure enough, Johnson sent me a link to a New York Times story stating that “a shocking amount of what we’re reading is created not by humans, but by computer algorithms” and that there is now an entire industry of “automated narrative generation” creating “human-sounding stories in whatever voice--from staid to sassy.” The AP and Forbes magazine currently use this software to generate business reports. Excuse me while I go huddle in a corner and cry for my profession.)\nQ: Great, now there's another reason my job might go away!\nA: Think about it this way: We think we've cornered the market on thinking and reasoning; machines are changing that.\nThere's another element to this, and that is in the design of products that are meant to create a personal experience between people and their machines. We have a little bit of that with Siri, which gives you a sense that what you're dealing with is not just a thing, but something that is personable. Then you also have companies like Mattel, which just announced the soon-to-be-released Barbie that interacts with children by having conversations with them.\nChicago Humanities Festival events: Staff picks Manual Cinema: \"My Soul's Shadow\": Lots of multimedia performance troupes describe their work as cinematic. The Chicago-based collective Manual Cinema stakes its very name on it. The production \"My Soul's Shadow\" takes its imagery from the life and writing of Federico Garcia Lorca (\"Blood Wedding,\"...\nManual Cinema: \"My Soul's Shadow\": Lots of multimedia performance troupes describe their work as cinematic. The Chicago-based collective Manual Cinema stakes its very name on it. The production \"My Soul's Shadow\" takes its imagery from the life and writing of Federico Garcia Lorca (\"Blood Wedding,\"...\nRead the story Q: Is this new? The Chatty Cathy dolls from the 1960s could talk. You'd pull a string and it would say things like, \"Mama\" or \"I'm thirsty.\" You're saying this doll is ...\nA: No, this doll is scary . It's: \"How was your day, Nina?\" And you can say, \"Oh, it was really bad,\" and Barbie will say, \"Well, I'm sorry to hear that.\" And that conversation can go down several layers. It uses something similar to what your phone uses, so it relays back to the cloud, and that information is processed by these massive processing systems and they send back a response to the Barbie.\nThe point of that interaction is to give the sense to this child that what they're interacting with is something empathetic, that cares about them, that is personable. This Mattel doll is engineered to give them some wise counsel. If they're being bullied in school, it knows how to say something like, \"Well, you should really focus on your positive aspects. Sometimes people make fun of us and that isn't fair, so you really shouldn't take that to heart.\" That's the kind of conversation Barbie is going to be having.\nQ: An entire generation is being groomed not just to accept but to expect to have that kind of relationship with a machine.\nA: And we are already there. It's not just children. Most people now who have a smartphone like the idea of being able to talk to it. So that philosophical aspect — lots of technologists and humanities scholars are looking at this impending crisis of what it means for the category of \"human,\" given the rise of intelligent machines.\nQ: Why is that a question? Do you think we as humans will go into some kind of existential panic if we don't feel that we can distinguish ourselves from machines?\nA: Yes. We're not quite in panic mode yet. Most people are not even thinking about this question, but in less than 10 years, people who thought they had no interest in artificial intelligence are going to be pulled into it for various reasons.\nThere are so many moral aspects. Most of the research and development in artificial intelligence is actually for military applications. If machines are able to determine who an enemy subject is, and if they can actually fire on that subject and kill them, which they can , who is responsible for the killing of that person?\nThink about autonomous vehicles: If your car can decide which route to take and you just get inside and you're not telling the car where to go and you're not telling the car when to change lanes — what if there is an accident? Who is responsible? In fact, we have cars now that actually override the agency of human drivers in order to save lives. That's already happening.\nGoogle has the best-known autonomous cars, but Volvo has the technology right now, Mercedes has it, Honda has it. ( And Tesla .) Let's say you're approaching the vehicle in front of you and for whatever reason you're on the phone or changing the radio station and you're pressing the accelerator. The car just ignores you and it stops.\nQ: Even though drone pilots don't experience warfare in person, a lot of them suffer from PTSD, so I could see the military really liking the idea of removing the human element.\nA: When humans are taken out of the loop, it will be for very compelling reasons. The machines are so much faster, that if you wait for a human to decide, then you're not actually saving lives.\nQ: Advancements happen at a gradual pace, so we're not really getting freaked out about this new technology. Are we like the frog in the pot of water that's slowly coming to a boil — we won't realize there is a problem until it's too late?\nA: I think that's true, to an extent. People are constantly recalibrating and so everything seems to be making sense.\nBut the issue is that these advancements are happening more and more quickly. I was just reading about a medical patient who had not walked for 18 years and surgeons finally figured out how to use a technology that takes his brain signals and bypasses his spinal cord and goes directly to his muscles. He has a very awkward-looking electrode helmet that they put on his head so that he could do this, so the next step is actually to get this to the point where it can be inserted into his brain stem and interfaced directly with his neural network.\nThis gets us into another thing: What happens with the hybrids? When people are actually joined with machines? That's actually going to surpass the people-versus-machine dilemma. And it will happen because of the biomedical applications. How much intervention and combination of people and machines is too much? At what point do you stop being human?\nQ: Right now machines do our bidding. We can still boss computers around and you don't have to be polite! Will we come to a point where you go to look up directions and your phone refuses to help because you were a jerk last night and dropped it on the floor?\nA: That's one of the million-dollar questions. A lot of sci-fi deals with this. In \"The Terminator,\" the machines basically say, \"To heck with these humans — in fact, we're going to do our own thing and just eliminate the humans.\" Stephen Hawking has said that these machines are actually going to kill us. If we don't first figure out how to control strong AI machines that are engineered to be cognitive on the scale of humans, if we don't figure out what to do before we reach that point, we're only promising ourselves human extinction.\nThe research and development is not stopping. One of the things I'll be talking about is IBM Watson, which is the first commercially deployed cognitive computer. They have so many applications with this, it's so impressive. They want to use Watson to help figure out how to cure cancer. What they don't talk about so much is TrueNorth, which is part of DARPA (Defense Advanced Research Projects Agency) at the Pentagon. They're trying to create a digital neuromorphic brain for a drone. And here is the moral thing: These machines won't need to learn how to kill people, we've already engineered them to kill people.\nSo, where is the room to stop and have the debate? We can have debate — and we are having those discussions — but most of the AI, around 80 percent of it is in the military. It's an arms race, so no one at the Pentagon is saying, \"You know what? We really don't know what is going to happen, so let's just clamp down on everything and stop all of our programs and try to figure out the moral questions first.\"\nQ: The thing with autonomous machines, how do we even know what would motivate a machine? I mean, what would they be striving for — money, power, love? These are all human urges and drives. It seems faulty to use human psychology on machines. How can we even begin to guess what machines would want?\nA: That’s a great question. We really don’t know! It’s certainly true that these military killing machines are being engineered to preserve themselves and to kill anyone or anything that might attack them.\nBut as you increase the sophistication of the cognitive routines that these machines perform, how many of them are going to decide that they’re not going to do something that a human tells them to do?\nQ: The machine ignores you? Ugh, just like a person would.\nA: IMB will tell you, you don’t program Watson, you work with Watson. That’s technology we have now, so if we’re successful at taking that further, then we’re engineering them to be capable of not doing what we tell them.\nBut you’re asking about drives and the answer is, we don’t really know. If the engineering is about knowing how to learn — and to be able to change and evolve — this creates a quandary because there is no way that you could ever guarantee a machine will do what you want it to.\nWe shouldn’t be shocked if we’re successful and machines eventually can make their own decisions. And then the question is: What happens then?\nQ: “The Matrix”!\nA: Right, we’ll all be nutrition sacks imagining that we’re living fulfilling lives while the machines are just feeding on us! (Laughs) So once you begin to appreciate the direction R&D is taking, it’s at least worth paying attention to the kinds of concerns that are being raised.\nIf you think about the potential of human-machine hybrids — the increased ability to see or hear, or you might get a smart heart — will we get a type of racialization of people who have the money to have their kids neurally enhanced at a cost of $350,000.\nQ: A separate class of people who are super-humans? Technology that improves your memory or your ability to learn faster? That would be the equivalent of performance-enhancing drugs.\nA: Exactly. And the argument is going to be: If someone has the money to do this, shouldn’t they have the right? Who are you to deny me the right to improve my kid’s life? If you say we can’t enhance our kids by giving them a neural implant, are you going to take away all the other things parents do the enhance their kids’ chances of doing well — the private tutors, the private schools, all of that?\nSo it’s easy to see that what at first might seem very far-fetched could actually become a very mainstream contention that we might soon have to deal with.\nQ: What’s your take on movies that deal with this, like “Her”? Are they more than entertainment — not just movies but good question-posers about our future?\nA: I think art has always served that function. “Her” and “Transcendence” and “Terminator Genisys,” “Ex Machina” — there’s a reason why these movies are coming out right now, because our society is changing and reaching an inflection point. I do think that these films are very useful for providing us a way to think about the possibilities.\nI thought “Her” was far-fetched until I started studying about IBM’s Watson about two weeks after I saw the movie and I watched one of the senior VP’s of IBM, Mike Rhodin, interact with Watson at one of their conferences and it looked eerily similar to “Her”—I mean, a conversation with Watson in real time and Watson was being creative. He asked Watson for one thing and Watson gave him something else because Watson thought it was a better idea.\nQ: Does Watson pass the Turing Test, where a computer exhibits intelligent behavior and conversation that is indistinguishable from that of a human?\nA: No, not yet — but Mike Rhodin has said he gave a mandate to Watson’s engineers for Watson to pass the U.S. medical licensing exam.\nQ: Wait, so Watson would be able to become a board certified physician?\nA: I don’t know if a medical board would give Watson a certificate, but the reality is that doctors are already working with Watson. Watson is studying oncology at the Memorial Sloan Kettering Cancer Center in New York City right now.\nQ: Well, then all these other questions come up: If machines become autonomous and have cognitive abilities, do they have rights? Can they vote? Or serve in public office?\nA: It seems ridiculous at first, but when you actually see what the R&D is, it is at least unsettling and maybe a little exciting and certainly provocative in so many ways.\nSylvester Johnson's \"Of Machines and Men\" talk for the Humanities Festival takes place at 2:30 p.m. Oct. 24 at Northwestern University's Harris Hall (room 107), 1881 Sheridan Road in Evanston. Go to www.chicagohumanities.org .\nnmetz@tribpub.com\nTwitter @NinaMetzNews\nCopyright © 2015, Chicago Tribune Mattel Inc. Entertainment", "external_links": ["http://www.trbimg.com/img-56211e8a/turbine/ct-humanities-festival-sylvester-johnson-ae-1018-20151015", "http://www.trbimg.com/img-562109a7/turbine/ct-preview-humanities-festival-ae-1018-20151015", "http://www.nytimes.com/2015/03/08/opinion/sunday/if-an-algorithm-wrote-this-how-would-you-even-know.html", "http://autoweek.com/article/car-news/tesla-enables-autopilot-model-s-promises-world-without-steering-wheels", "http://www.trbimg.com/img-56200e3b/turbine/ct-ae-1018-humanities-critics-picks-20151015"], "published": "2015-10-16T19:54:00.000+03:00", "crawled": "2015-10-18T16:20:26.000+03:00", "highlightTitle": ""}